import copy
from tqdm import tqdm
import pandas as pd
import numpy as np
from utils import squeeze


def get_tfidf(data: pd.DataFrame, vocab: list, indices: list = None, save_path: str=None, encoding: str='euc-kr') -> pd.DataFrame:
    """tf-idf matrixë¥¼ ë¦¬í„´í•˜ëŠ” í•¨ìˆ˜. ì„œë¸Œìƒ˜í”Œë§ì„ í†µí•´ ì¼ë¶€ ë°ì´í„°ì…‹ì— ëŒ€í•´ì„œë§Œ tf-idfë¥¼ êµ¬í•  ìˆ˜ ìˆìŒ
    tf-idf ë°©ì‹
        - tf: boolean
        - idf: logarithmic
        - Reference: https://ko.wikipedia.org/wiki/Tf-idf
    Args:
        data (pd.DataFrame): ì „ì²´ ë°ì´í„°ì…‹
        vocab (list): TF-IDFë¥¼ ë§¤ê¸¸ íƒœê·¸ ë¦¬ìŠ¤íŠ¸
        indices (list, optional): ìƒ˜í”Œë§í•  ê²½ìš° í™œìš©. ilocì— ì‚¬ìš©ë  ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸ë¥¼ ì…ë ¥(ì •ìˆ˜ë¡œ ë‹¨ì¼ ìƒ˜í”Œë§ë„ ê°€ëŠ¥). Defaults to None.

    Returns:
        pd.DataFrame: ì‚¬ì´ì¦ˆê°€ (data size, vocab_size)ì¸ TF-IDF matrix
    """
    if isinstance(indices, int):
        indices = [indices]

    num_docs = data.shape[0]
    batch = copy.deepcopy(data) if indices is None else data.iloc[indices, :]

    idf = get_idf(batch=batch, vocab=vocab, num_docs=num_docs)
    tf = get_tf(batch=batch, vocab=vocab)

    print("Aggregating TF and IDF...")
    output = tf * idf.values # broad-casting

    if save_path is not None:
        print('Saving TF-IDF...', end='    ')
        post_id_list = batch['post_id'].tolist()
        output.index = post_id_list
        output = output.reset_index().rename({'index': 'post_id'}, axis=1)
        output.to_csv(save_path, encoding=encoding, index=False)
        print(f'saved as "{save_path}"ğŸ˜')
    else:
        return output


def get_idf(batch: pd.DataFrame, vocab: list, num_docs: int) -> pd.DataFrame:
    """batch ë°ì´í„°ì˜ IDF ë¦¬í„´
        - IDF ë°©ì‹: logarithmic
        - Reference: https://ko.wikipedia.org/wiki/Tf-idf

    Args:
        batch (pd.DataFrame): metadataì˜ ì¼ë¶€
        vocab (list): IDFì— í™œìš©í•  í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
        num_docs (int): metadata(ëª¨ì§‘ë‹¨)ì˜ ëª¨ë“  ë¬¸ì„œ, ì¦‰ í–‰ì˜ ê°œìˆ˜

    Returns:
        pd.DataFrame: (1, vocab ìˆ˜) í¬ê¸°ì˜ IDF í–‰ë ¬
    """    
    vocab_size = len(vocab)
    idf = pd.DataFrame(np.zeros((1, vocab_size)), columns=vocab)

    kwd_list = set(squeeze(batch["keyword_list"].tolist()))
    kwd_list_filtered = list(filter(lambda x: x in vocab, kwd_list))

    pbar = tqdm(kwd_list_filtered)
    pbar.set_description("Getting IDF")
    for tag in pbar:
        if tag in vocab:
            idf[tag] = np.log(num_docs) - np.log(
                sum(batch["keyword_list"].apply(lambda x: tag in x))
            )

    return idf


def get_tf(batch: pd.DataFrame, vocab: list) -> pd.DataFrame:
    """batch ë°ì´í„°ì˜ tfë¥¼ ë¦¬í„´
        - tf ë°©ì‹: boolean
        - Reference: https://ko.wikipedia.org/wiki/Tf-idf

    Args:
        batch (pd.DataFrame): metadataì˜ ì¼ë¶€
        vocab (list): TFì— í™œìš©í•  í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸

    Returns:
        pd.DataFrame: (batch ë°ì´í„° row ìˆ˜, vocab ìˆ˜) í¬ê¸°ì˜ TF í–‰ë ¬
    """    
    vocab_size = len(vocab)
    tf = pd.DataFrame(np.zeros((batch.shape[0], vocab_size)), columns=vocab)

    # split two cases because of vesion issue
    try:
        tqdm.pandas(desc="Getting TF")
        tf = tf.progress_apply(lambda x: _sparkle(x, batch, vocab), axis=1)
    except ImportError:
        print("Getting TF...")
        tf = tf.apply(lambda x: _sparkle(x, batch, vocab), axis=1)

    return tf


def _sparkle(row: pd.DataFrame, batch: pd.DataFrame, vocab: list):
    """boolean-type TFë¥¼ êµ¬í•˜ëŠ” í•¨ìˆ˜. get_tfidf() ë‚´ë¶€ì—ì„œ ë‹¤ìŒê³¼ ê°™ì€ í˜•íƒœë¡œ í™œìš©

        output.apply(lambda x: onehot(x, sample), axis=1)

    Args:
        sample_row (pd.Series): apply í•¨ìˆ˜ê°€ ì ìš©ëœ ìƒ˜í”Œ ë°ì´í„°ì˜ ê° í–‰
        sample (pd.DataFrame): ìƒ˜í”Œ ë°ì´í„°. í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ ì •ë³´ë¥¼ ì–»ê¸° ìœ„í•´ í™œìš©

    Returns:
        [type]: [description]
    """
    idx = row.name
    for tag in batch["keyword_list"].iloc[idx]:
        if tag in vocab:
            row[tag] += 1
    return row


# deprecated: too slow
# def get_tfidf(data, vocab: list, indices: list=None, tf_type: str='boolean'):
#     if isinstance(indices, int):
#         indices = [indices]
#     vocab_size = len(vocab)
#     num_docs = data.shape[0]
#     sample = copy.deepcopy(data) if indices is None else data.iloc[indices, :]
#     output = pd.DataFrame(np.zeros((sample.shape[0], vocab_size)), columns=vocab)

#     if tf_type == 'boolean':
#         tf = 1 # boolean tf
#         output.apply(lambda )
#         for _, row in sample.iterrows():
#             tfidf = dict().fromkeys(vocab)
#             for tag in row['keyword_list']:
#                 idf = np.log(num_docs / sum(sample['keyword_list'].apply(lambda x: tag in x)))
#                 tfidf[tag] = tf * idf
#             output = output.append(tfidf, ignore_index=True)
#     else:
#         raise NotImplementedError()

#     return output
