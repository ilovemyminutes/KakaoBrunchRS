{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import pickle\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from glob import glob\n",
    "from collections import Counter, defaultdict\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from load_data import load_user_time_read, load_raw\n",
    "from tfidf import TFIDFGenerator, get_df\n",
    "from config import Config\n",
    "from utils import iterate_data_files, squeeze, save_as_pickle\n",
    "from preprocessing import PostIdEncoder\n",
    "from utils import squeeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = [open('../preprocessed/train', 'r').readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading time: 18.295762062072754\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "user_time_read = load_user_time_read(root_dir='../preprocessed/user_time_read.json')\n",
    "encoder = PostIdEncoder(root_dir='../encodings')\n",
    "tfidf = TFIDFGenerator('../tfidf')\n",
    "print(f'Loading time: {time.time() - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start = '2018100100'\n",
    "train_end = '2019022200'\n",
    "dev_start = '2019022200'\n",
    "dev_end = '2019030100'\n",
    "\n",
    "# set user list\n",
    "dev_user_list = []\n",
    "for daily in dev:\n",
    "    users = [u.split()[0] for u in daily]\n",
    "    dev_user_list.extend(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Extracting user prefereces based on 2018100100-2019022200:  21%|██▏       | 3/14 [00:00<00:00, 26.26it/s]Getting User Preferences of Batch #0...\n",
      "Extracting user prefereces based on 2018100100-2019022200: 100%|██████████| 14/14 [00:02<00:00,  6.86it/s]\n",
      "Postprocessing...\n"
     ]
    }
   ],
   "source": [
    "def filter_read_by_time(history, start, end):\n",
    "    history_filtered = list(filter(lambda x: (int(start) <= int(x[0].split('_')[0])) and (int(end) >= int(x[0].split('_')[-1])), history))\n",
    "    return history_filtered\n",
    "\n",
    "start = Config.train_start\n",
    "end = Config.train_end\n",
    "n_splits = 20000\n",
    "batch_size = len(dev_user_list) // n_splits\n",
    "\n",
    "for i in range(n_splits):\n",
    "    print(f'Getting User Preferences of Batch #{i}...')\n",
    "    if i == n_splits-1:\n",
    "        dev_user_batch = dev_user_list[i*batch_size:]\n",
    "    else:\n",
    "        dev_user_batch = dev_user_list[i*batch_size:(i+1)*batch_size]\n",
    "\n",
    "    posts = pd.DataFrame()\n",
    "    user_preferences = np.zeros((7000, 1))\n",
    "\n",
    "    for user_id in tqdm(dev_user_batch, desc=f'Extracting user prefereces based on {start}-{end}'):\n",
    "        history = filter_read_by_time(user_time_read[user_id], start, end)\n",
    "        history = squeeze(list(map(lambda x: x[-1], history)))\n",
    "        \n",
    "        user_tfidf = tfidf.generate(encoder.transform(history), drop_id=False)\n",
    "        preference = user_tfidf.drop('post_meta_id', axis=1).values.sum(axis=0)\n",
    "\n",
    "        posts = pd.concat([posts, user_tfidf], axis=0, ignore_index=True)\n",
    "        user_preferences =np.hstack([user_preferences,preference.reshape(7000, 1)])\n",
    "\n",
    "    print('Postprocessing...')\n",
    "    user_preferences = user_preferences[:, 1:]\n",
    "    posts = posts.drop_duplicates(ignore_index=True)\n",
    "    post_meta_id = posts['post_meta_id'].tolist()\n",
    "    posts = posts.drop('post_meta_id', axis=1)\n",
    "    idf = np.log(tfidf.DF.values.squeeze()) - np.log((posts != 0).sum().values + 1e-4)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Extracting user prefereces based on 2018100100-2019022200: 100%|██████████| 100/100 [46:26<00:00, 27.87s/it]\n",
      "Postprocessing...\n"
     ]
    }
   ],
   "source": [
    "def filter_read_by_time(history, start, end):\n",
    "    history_filtered = list(filter(lambda x: (int(start) <= int(x[0].split('_')[0])) and (int(end) >= int(x[0].split('_')[-1])), history))\n",
    "    return history_filtered\n",
    "\n",
    "def calculate_export_user_preferences(start: str=Config.train_start, end: str=Config.train_end, n_splits: int=50, save_path: str='./offline_tasks/user_preferences'):\n",
    "    print('Loading tools...', end='\\t')\n",
    "    dev_raw = [open('./preprocessed/train', 'r').readlines()]\n",
    "    dev_user_list = []\n",
    "    for daily in dev_raw:\n",
    "        users = [u.split()[0] for u in daily]\n",
    "        dev_user_list.extend(users)\n",
    "\n",
    "    user_time_read = load_user_time_read(root_dir='./preprocessed/user_time_read.json')\n",
    "    encoder = PostIdEncoder(root_dir='./encodings')\n",
    "    tfidf = TFIDFGenerator('./tfidf')\n",
    "    print('loaded!')\n",
    "\n",
    "    batch_size = len(dev_user_list) // n_splits\n",
    "\n",
    "    for i in range(n_splits):\n",
    "        print(f'Getting User Preferences of Batch #{i}...')\n",
    "        if i == n_splits-1:\n",
    "            dev_user_batch = dev_user_list[i*batch_size:]\n",
    "        else:\n",
    "            dev_user_batch = dev_user_list[i*batch_size:(i+1)*batch_size]\n",
    "\n",
    "        posts = pd.DataFrame()\n",
    "        user_preferences = np.zeros((7000, 1))\n",
    "\n",
    "        for user_id in tqdm(dev_user_batch, desc=f'Extracting user prefereces based on {start}-{end}'):\n",
    "            history = filter_read_by_time(user_time_read[user_id], start, end)\n",
    "            preference = np.zeros((1, 7000))\n",
    "            for h in history:\n",
    "                partial_tfidf = tfidf.generate(encoder.transform(h[-1]), drop_id=False)\n",
    "                preference += partial_tfidf.drop('post_meta_id', axis=1).values.sum(axis=0)\n",
    "                posts = pd.concat([posts, partial_tfidf], axis=0, ignore_index=True)\n",
    "            user_preferences = np.hstack([user_preferences, preference.reshape(7000, 1)])\n",
    "\n",
    "        print('Postprocessing...')\n",
    "        user_preferences = user_preferences[:, 1:]\n",
    "        posts = posts.drop_duplicates(ignore_index=True)\n",
    "        post_meta_id = posts['post_meta_id'].tolist()\n",
    "        posts = posts.drop('post_meta_id', axis=1)\n",
    "        idf = np.log(tfidf.DF.values.squeeze()) - np.log((posts != 0).sum().values + 1e-4)\n",
    "\n",
    "        print('Saving...')\n",
    "        batch_name = f'({start}-{end})batch{i+1:0>2d}'\n",
    "        os.mkdir(os.path.join(save_path, batch_name))\n",
    "        save_npz(os.path.join(save_path, batch_name, f'posts{i+1:0>2d}.npz'), csr_matrix(posts.values))\n",
    "        save_as_pickle(post_meta_id, os.path.join(save_path, batch_name, f'post_meta_id{i:0>2d}.pkl'))\n",
    "        np.save(os.path.join(save_path, batch_name, f'idf{i+1:0>2d}.npy'), idf)\n",
    "        np.save(os.path.join(save_path, batch_name, f'user_preferences{i+1:0>2d}.npy'), user_preferences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_output = np.matmul((posts * idf).values, user_preferences)\n",
    "enc = PostIdEncoder(root_dir='../encodings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('test_recommend.npy', recommend_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_output_user = pd.DataFrame(dict(value=recommend_output[:, 1], id=post_meta_id)).sort_values(by='value', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_output_user['id'] = recommend_output_user['id'].apply(lambda x: enc.inverse_transform(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             value                   id\n",
       "39   322457.075150  @englishspeaking_66\n",
       "56   313143.167282         @linecard_45\n",
       "60   313143.167282         @linecard_43\n",
       "57   313143.167282         @linecard_42\n",
       "98   312260.888493         @linecard_77\n",
       "..             ...                  ...\n",
       "103  188480.532344           @hygo92_85\n",
       "82   184787.498120         @muncoach_25\n",
       "206  184734.588007        @thepiano_114\n",
       "131  184527.611553        @thepiano_106\n",
       "140  184499.304356           @nonie1_35\n",
       "\n",
       "[100 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>value</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>39</th>\n      <td>322457.075150</td>\n      <td>@englishspeaking_66</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>313143.167282</td>\n      <td>@linecard_45</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>313143.167282</td>\n      <td>@linecard_43</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>313143.167282</td>\n      <td>@linecard_42</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>312260.888493</td>\n      <td>@linecard_77</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>103</th>\n      <td>188480.532344</td>\n      <td>@hygo92_85</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>184787.498120</td>\n      <td>@muncoach_25</td>\n    </tr>\n    <tr>\n      <th>206</th>\n      <td>184734.588007</td>\n      <td>@thepiano_114</td>\n    </tr>\n    <tr>\n      <th>131</th>\n      <td>184527.611553</td>\n      <td>@thepiano_106</td>\n    </tr>\n    <tr>\n      <th>140</th>\n      <td>184499.304356</td>\n      <td>@nonie1_35</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "recommend_output_user.head(100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}